{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import urllib.request \n",
    "import bs4\n",
    "\n",
    "from tqdm import tqdm\n",
    "from lxml import html\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 메인 데이터(재비산먼지 농도) 수집 및 기본 처리\n",
    "\n",
    "* API 인증키 에러가 지속되어 csv 파일로 하나씩 다운로드 받음(67개의 파일)\n",
    "* 디렉토리 내의 파일들 모두 불러와 같은 형식으로 하나의 데이터프레임으로 합침\n",
    "    * `date`에 연도가 붙지 않고 들어오는 데이터의 경우 임의로 붙여서 같은 형태 유지하도록 함\n",
    "* '서울시'의 데이터만 활용 -> 메인 데이터프레임 별도 파일로 저장\n",
    "* [링크](https://www.data.go.kr/data/15021888/fileData.do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'dust_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = os.listdir(dirname)\n",
    "# full_df = []\n",
    "# # 컬럼의 순서는 같지만, 이름이 달라 모두 같은 형식으로 통일\n",
    "# columns = ['date', 'time', 'city', 'gu', 'road', 'start', 'end', 'temperature', 'humidity', 'avg_re_dust', 'dust_ratio']\n",
    "# for k, filename in enumerate(filenames):\n",
    "#     full_filename = os.path.join(dirname, filename)\n",
    "#     df = pd.read_csv(full_filename, encoding='cp949')\n",
    "#     df.columns = columns\n",
    "#     # `date` 형식이 다른 파일이 있어, 해당 파일은 전처리 후 합침\n",
    "#     if len(df['date'][0]) != 10:\n",
    "#         year = re.search(r\"\\d{4}\", filename).group()\n",
    "#         df['date'] = df['date'].apply(lambda x: year+'-'+x)\n",
    "#     if k == 0:\n",
    "#         # 첫 파일의 경우 합칠 데이터가 없어 그대로 데이터프레임 반환\n",
    "#         full_df = df\n",
    "#     else:\n",
    "#         full_df = pd.concat([full_df, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울시 데이터만 활용할 예정\n",
    "# seoul_df = full_df[full_df['city']=='서울']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 별도의 파일로 저장\n",
    "# seoul_df.to_csv('../data/seoul_re_dust.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seoul_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seoul_df = pd.read_csv('../data/seoul_re_dust.csv', index_col=0)\n",
    "seoul_df['date_cd'] = seoul_df['date'].apply(lambda x: \"\".join(x.split('-')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 서울시 생활인구 데이터 수집 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# living_df = []\n",
    "# for idx, date_cd in tqdm(enumerate(seoul_df['date_cd'].unique())):\n",
    "#     living_api = f'http://openapi.seoul.go.kr:8088/{os.environ[\"living_api\"]}/xml/SPOP_LOCAL_RESD_JACHI/1/600/{date_cd}'\n",
    "#     response = requests.get(living_api)\n",
    "#     contents = response.text\n",
    "\n",
    "#     xml_obj = bs4.BeautifulSoup(contents,'lxml-xml')\n",
    "#     rows = xml_obj.findAll('row')\n",
    "#     # 각 행의 컬럼, 이름, 값을 가지는 리스트 만들기\n",
    "#     row_list = [] # 행값\n",
    "#     name_list = [] # 열이름값\n",
    "#     value_list = [] #데이터값\n",
    "\n",
    "#     # xml 안의 데이터 수집\n",
    "#     for i in range(0, len(rows)):\n",
    "#         columns = rows[i].find_all()\n",
    "#         #첫째 행 데이터 수집\n",
    "#         for j in range(0,len(columns)):\n",
    "#             if i ==0:\n",
    "#                 # 컬럼 이름 값 저장\n",
    "#                 name_list.append(columns[j].name)\n",
    "#             # 컬럼의 각 데이터 값 저장\n",
    "#             value_list.append(columns[j].text)\n",
    "#         # 각 행의 value값 전체 저장\n",
    "#         row_list.append(value_list)\n",
    "#         # 데이터 리스트 값 초기화\n",
    "#         value_list=[]\n",
    "\n",
    "#     if idx == 0:\n",
    "#         living_df = pd.DataFrame(row_list, columns=name_list)\n",
    "#     else:\n",
    "#         living_df = pd.concat([living_df, pd.DataFrame(row_list, columns=name_list)], axis=0)\n",
    "\n",
    "# living_df.to_csv('living_origin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# living_df = pd.read_csv('living_origin.csv')\n",
    "# living_df['TOT_LVPOP_CO'] = living_df['TOT_LVPOP_CO'].astype(float)\n",
    "# living_df_summ = living_df.groupby(['STDR_DE_ID', 'ADSTRD_CODE_SE'])['TOT_LVPOP_CO'].mean()\n",
    "# living_df_new = living_df_summ.reset_index()\n",
    "# living_df_new.to_csv('../data/living_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# living_df = pd.read_csv('living_origin.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 미세먼지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_dust_df = []\n",
    "# for idx, date_cd in tqdm(enumerate(seoul_df['date_cd'].unique())):\n",
    "#     fine_dust_api = f'http://openapi.seoul.go.kr:8088/{os.environ[\"fine_dust_api\"]}/xml/DailyAverageCityAir/1/24/{date_cd}'\n",
    "#     response = requests.get(fine_dust_api)\n",
    "#     contents = response.text\n",
    "\n",
    "#     xml_obj = bs4.BeautifulSoup(contents,'lxml-xml')\n",
    "#     rows = xml_obj.findAll('row')\n",
    "#     # 각 행의 컬럼, 이름, 값을 가지는 리스트 만들기\n",
    "#     row_list = [] # 행값\n",
    "#     name_list = [] # 열이름값\n",
    "#     value_list = [] #데이터값\n",
    "\n",
    "#     # xml 안의 데이터 수집\n",
    "#     for i in range(0, len(rows)):\n",
    "#         columns = rows[i].find_all()\n",
    "#         #첫째 행 데이터 수집\n",
    "#         for j in range(0,len(columns)):\n",
    "#             if i ==0:\n",
    "#                 # 컬럼 이름 값 저장\n",
    "#                 name_list.append(columns[j].name)\n",
    "#             # 컬럼의 각 데이터 값 저장\n",
    "#             value_list.append(columns[j].text)\n",
    "#         # 각 행의 value값 전체 저장\n",
    "#         row_list.append(value_list)\n",
    "#         # 데이터 리스트 값 초기화\n",
    "#         value_list=[]\n",
    "\n",
    "#     if idx == 0:\n",
    "#         fine_dust_df = pd.DataFrame(row_list, columns=name_list)\n",
    "#     else:\n",
    "#         fine_dust_df = pd.concat([fine_dust_df, pd.DataFrame(row_list, columns=name_list)], axis=0)\n",
    "\n",
    "# fine_dust_df.to_csv('fine_dust_origin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_dust_df.to_csv('../data/fine_dust_df.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 건설현장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contsruct_df = []\n",
    "\n",
    "# for idx in range(1, 5000, 1000):\n",
    "#     construct_api = f'http://openapi.seoul.go.kr:8088/{os.environ[\"construct_api\"]}/xml/ListOnePMISBizInfo/{idx}/{idx+999}/'\n",
    "#     response = requests.get(construct_api)\n",
    "#     contents = response.text\n",
    "\n",
    "#     xml_obj = bs4.BeautifulSoup(contents,'lxml-xml')\n",
    "#     rows = xml_obj.findAll('row')\n",
    "#     # 각 행의 컬럼, 이름, 값을 가지는 리스트 만들기\n",
    "#     row_list = [] # 행값\n",
    "#     name_list = [] # 열이름값\n",
    "#     value_list = [] #데이터값\n",
    "\n",
    "#     # xml 안의 데이터 수집\n",
    "#     for i in range(0, len(rows)):\n",
    "#         columns = rows[i].find_all()\n",
    "#         #첫째 행 데이터 수집\n",
    "#         for j in range(0,len(columns)):\n",
    "#             if i ==0:\n",
    "#                 # 컬럼 이름 값 저장\n",
    "#                 name_list.append(columns[j].name)\n",
    "#             # 컬럼의 각 데이터 값 저장\n",
    "#             value_list.append(columns[j].text)\n",
    "#         # 각 행의 value값 전체 저장\n",
    "#         row_list.append(value_list)\n",
    "#         # 데이터 리스트 값 초기화\n",
    "#         value_list=[]\n",
    "\n",
    "#     if idx == 1:\n",
    "#         contsruct_df = pd.DataFrame(row_list, columns=name_list)\n",
    "#     else:\n",
    "#         contsruct_df = pd.concat([contsruct_df, pd.DataFrame(row_list, columns=name_list)], axis=0)\n",
    "\n",
    "# contsruct_df.to_csv('construct_origin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct_df = contsrtuct_df[['DU_DATE', 'OFFICE_ADDR']]\n",
    "# construct_df = construct_df[construct_df['OFFICE_ADDR'].apply(lambda x: True if \"서울\" in x else False)]\n",
    "\n",
    "# construct_df['cons_start_dt'] = construct_df['DU_DATE'].apply(lambda x: x.split(\"~\")[0])\n",
    "# construct_df['cons_end_dt'] = construct_df['DU_DATE'].apply(lambda x: x.split(\"~\")[1])\n",
    "# construct_df['gu'] = construct_df['OFFICE_ADDR'].apply(lambda x: x.split(\" \")[1])\n",
    "\n",
    "# construct_df = construct_df.drop(['DU_DATE', 'OFFICE_ADDR'], axis=1)\n",
    "# construct_df.to_csv('../data/contsruct_info.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 버스 승하차 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행정동 버스 승하차 정보는 2022년 01월 28일부터 데이터가 제공됨\n",
    "# seoul_df = seoul_df[seoul_df['date_cd']>='20220128']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [01:20,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# bus_df = []\n",
    "# for idx, date_cd in tqdm(enumerate(seoul_df['date_cd'].unique())):\n",
    "#     living_api = f'http://openapi.seoul.go.kr:8088/{os.environ[\"bus_api\"]}/xml/tpssEmdBus/1/424/{date_cd}'\n",
    "#     response = requests.get(living_api)\n",
    "#     contents = response.text\n",
    "\n",
    "#     xml_obj = bs4.BeautifulSoup(contents,'lxml-xml')\n",
    "#     rows = xml_obj.findAll('row')\n",
    "#     # 각 행의 컬럼, 이름, 값을 가지는 리스트 만들기\n",
    "#     row_list = [] # 행값\n",
    "#     name_list = [] # 열이름값\n",
    "#     value_list = [] #데이터값\n",
    "\n",
    "#     # xml 안의 데이터 수집\n",
    "#     for i in range(0, len(rows)):\n",
    "#         columns = rows[i].find_all()\n",
    "#         #첫째 행 데이터 수집\n",
    "#         for j in range(0,len(columns)):\n",
    "#             if i ==0:\n",
    "#                 # 컬럼 이름 값 저장\n",
    "#                 name_list.append(columns[j].name)\n",
    "#             # 컬럼의 각 데이터 값 저장\n",
    "#             value_list.append(columns[j].text)\n",
    "#         # 각 행의 value값 전체 저장\n",
    "#         row_list.append(value_list)\n",
    "#         # 데이터 리스트 값 초기화\n",
    "#         value_list=[]\n",
    "\n",
    "#     if idx == 0:\n",
    "#         bus_df = pd.DataFrame(row_list, columns=name_list)\n",
    "#     else:\n",
    "#         bus_df = pd.concat([bus_df, pd.DataFrame(row_list, columns=name_list)], axis=0)\n",
    "\n",
    "# bus_df.to_csv('bus_origin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bus_df.to_csv('../data/bus_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
